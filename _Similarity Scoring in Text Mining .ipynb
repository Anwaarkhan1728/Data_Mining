{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b95ec493-0550-4df7-a14e-7dd9bbc9283e",
   "metadata": {},
   "source": [
    "# **Load a Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b2b34a5-5d89-4c11-85cb-1526f2a412eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Text mining is fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Text mining helps extract insights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data science involves text mining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fun with machine learning and mining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial intelligence drives innovation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Machine learning is a subset of AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deep learning uses neural networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Text mining helps in data extraction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data science bridges statistics and computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Python is popular for data analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Big data requires scalable solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Clustering groups similar data points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Classification assigns labels to data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Natural Language Processing is fascinating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sentiment analysis identifies emotions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Recommendation systems suggest products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Regression predicts continuous values</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data visualization simplifies insights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Statistics is the foundation of data science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cloud computing supports data storage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data preprocessing is crucial for modeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Tokenization splits text into words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Vectorization represents text numerically</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cosine similarity measures text similarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Word embeddings capture word meanings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Neural networks learn from data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Optimization minimizes loss functions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Feature engineering improves model performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>EDA uncovers hidden patterns in data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         documents\n",
       "0                               Text mining is fun\n",
       "1               Text mining helps extract insights\n",
       "2                Data science involves text mining\n",
       "3             Fun with machine learning and mining\n",
       "4        Artificial intelligence drives innovation\n",
       "5               Machine learning is a subset of AI\n",
       "6               Deep learning uses neural networks\n",
       "7             Text mining helps in data extraction\n",
       "8    Data science bridges statistics and computing\n",
       "9              Python is popular for data analysis\n",
       "10            Big data requires scalable solutions\n",
       "11           Clustering groups similar data points\n",
       "12           Classification assigns labels to data\n",
       "13      Natural Language Processing is fascinating\n",
       "14          Sentiment analysis identifies emotions\n",
       "15         Recommendation systems suggest products\n",
       "16           Regression predicts continuous values\n",
       "17          Data visualization simplifies insights\n",
       "18    Statistics is the foundation of data science\n",
       "19           Cloud computing supports data storage\n",
       "20      Data preprocessing is crucial for modeling\n",
       "21             Tokenization splits text into words\n",
       "22       Vectorization represents text numerically\n",
       "23      Cosine similarity measures text similarity\n",
       "24           Word embeddings capture word meanings\n",
       "25                 Neural networks learn from data\n",
       "26           Optimization minimizes loss functions\n",
       "27  Feature engineering improves model performance\n",
       "28            EDA uncovers hidden patterns in data"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example dataset\n",
    "data = {\n",
    "    \"documents\": [\n",
    "        \"Text mining is fun\",\n",
    "        \"Text mining helps extract insights\",\n",
    "        \"Data science involves text mining\",\n",
    "        \"Fun with machine learning and mining\",\n",
    "        \"Artificial intelligence drives innovation\",\n",
    "        \"Machine learning is a subset of AI\",\n",
    "        \"Deep learning uses neural networks\",\n",
    "        \"Text mining helps in data extraction\",\n",
    "        \"Data science bridges statistics and computing\",\n",
    "        \"Python is popular for data analysis\",\n",
    "        \"Big data requires scalable solutions\",\n",
    "        \"Clustering groups similar data points\",\n",
    "        \"Classification assigns labels to data\",\n",
    "        \"Natural Language Processing is fascinating\",\n",
    "        \"Sentiment analysis identifies emotions\",\n",
    "        \"Recommendation systems suggest products\",\n",
    "        \"Regression predicts continuous values\",\n",
    "        \"Data visualization simplifies insights\",\n",
    "        \"Statistics is the foundation of data science\",\n",
    "        \"Cloud computing supports data storage\",\n",
    "        \"Data preprocessing is crucial for modeling\",\n",
    "        \"Tokenization splits text into words\",\n",
    "        \"Vectorization represents text numerically\",\n",
    "        \"Cosine similarity measures text similarity\",\n",
    "        \"Word embeddings capture word meanings\",\n",
    "        \"Neural networks learn from data\",\n",
    "        \"Optimization minimizes loss functions\",\n",
    "        \"Feature engineering improves model performance\",\n",
    "        \"EDA uncovers hidden patterns in data\",\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850d24bb-a89d-4cfe-b036-d61d62e67604",
   "metadata": {},
   "source": [
    "# **Preprocess the Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df48e417-3122-44b2-a9d3-84eee5bc63b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove punctuation\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text.strip()\n",
    "\n",
    "df['cleaned_documents'] = df['documents'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e744b6b0-6fe5-42a2-be7b-b514295f0e3e",
   "metadata": {},
   "source": [
    "# **Apply Cosine Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a9dcab1-2529-41c3-9437-7878278ec1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix:\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "          0         1         2         3    4         5         6         7   \\\n",
      "0   1.000000  0.447214  0.447214  0.408248  0.0  0.204124  0.000000  0.408248   \n",
      "1   0.447214  1.000000  0.400000  0.182574  0.0  0.000000  0.000000  0.547723   \n",
      "2   0.447214  0.400000  1.000000  0.182574  0.0  0.000000  0.000000  0.547723   \n",
      "3   0.408248  0.182574  0.182574  1.000000  0.0  0.333333  0.182574  0.166667   \n",
      "4   0.000000  0.000000  0.000000  0.000000  1.0  0.000000  0.000000  0.000000   \n",
      "5   0.204124  0.000000  0.000000  0.333333  0.0  1.000000  0.182574  0.000000   \n",
      "6   0.000000  0.000000  0.000000  0.182574  0.0  0.182574  1.000000  0.000000   \n",
      "7   0.408248  0.547723  0.547723  0.166667  0.0  0.000000  0.000000  1.000000   \n",
      "8   0.000000  0.000000  0.365148  0.166667  0.0  0.000000  0.000000  0.166667   \n",
      "9   0.204124  0.000000  0.182574  0.000000  0.0  0.166667  0.000000  0.166667   \n",
      "10  0.000000  0.000000  0.200000  0.000000  0.0  0.000000  0.000000  0.182574   \n",
      "11  0.000000  0.000000  0.200000  0.000000  0.0  0.000000  0.000000  0.182574   \n",
      "12  0.000000  0.000000  0.200000  0.000000  0.0  0.000000  0.000000  0.182574   \n",
      "13  0.223607  0.000000  0.000000  0.000000  0.0  0.182574  0.000000  0.000000   \n",
      "14  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
      "15  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
      "16  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
      "17  0.000000  0.223607  0.223607  0.000000  0.0  0.000000  0.000000  0.204124   \n",
      "18  0.188982  0.000000  0.338062  0.000000  0.0  0.308607  0.000000  0.154303   \n",
      "19  0.000000  0.000000  0.200000  0.000000  0.0  0.000000  0.000000  0.182574   \n",
      "20  0.204124  0.000000  0.182574  0.000000  0.0  0.166667  0.000000  0.166667   \n",
      "21  0.223607  0.200000  0.200000  0.000000  0.0  0.000000  0.000000  0.182574   \n",
      "22  0.250000  0.223607  0.223607  0.000000  0.0  0.000000  0.000000  0.204124   \n",
      "23  0.188982  0.169031  0.169031  0.000000  0.0  0.000000  0.000000  0.154303   \n",
      "24  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
      "25  0.000000  0.000000  0.200000  0.000000  0.0  0.000000  0.400000  0.182574   \n",
      "26  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
      "27  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
      "28  0.000000  0.000000  0.182574  0.000000  0.0  0.000000  0.000000  0.333333   \n",
      "\n",
      "          8         9   ...        19        20        21        22        23  \\\n",
      "0   0.000000  0.204124  ...  0.000000  0.204124  0.223607  0.250000  0.188982   \n",
      "1   0.000000  0.000000  ...  0.000000  0.000000  0.200000  0.223607  0.169031   \n",
      "2   0.365148  0.182574  ...  0.200000  0.182574  0.200000  0.223607  0.169031   \n",
      "3   0.166667  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4   0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "5   0.000000  0.166667  ...  0.000000  0.166667  0.000000  0.000000  0.000000   \n",
      "6   0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "7   0.166667  0.166667  ...  0.182574  0.166667  0.182574  0.204124  0.154303   \n",
      "8   1.000000  0.166667  ...  0.365148  0.166667  0.000000  0.000000  0.000000   \n",
      "9   0.166667  1.000000  ...  0.182574  0.500000  0.000000  0.000000  0.000000   \n",
      "10  0.182574  0.182574  ...  0.200000  0.182574  0.000000  0.000000  0.000000   \n",
      "11  0.182574  0.182574  ...  0.200000  0.182574  0.000000  0.000000  0.000000   \n",
      "12  0.182574  0.182574  ...  0.200000  0.182574  0.000000  0.000000  0.000000   \n",
      "13  0.000000  0.182574  ...  0.000000  0.182574  0.000000  0.000000  0.000000   \n",
      "14  0.000000  0.204124  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "15  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "16  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "17  0.204124  0.204124  ...  0.223607  0.204124  0.000000  0.000000  0.000000   \n",
      "18  0.462910  0.308607  ...  0.169031  0.308607  0.000000  0.000000  0.000000   \n",
      "19  0.365148  0.182574  ...  1.000000  0.182574  0.000000  0.000000  0.000000   \n",
      "20  0.166667  0.500000  ...  0.182574  1.000000  0.000000  0.000000  0.000000   \n",
      "21  0.000000  0.000000  ...  0.000000  0.000000  1.000000  0.223607  0.169031   \n",
      "22  0.000000  0.000000  ...  0.000000  0.000000  0.223607  1.000000  0.188982   \n",
      "23  0.000000  0.000000  ...  0.000000  0.000000  0.169031  0.188982  1.000000   \n",
      "24  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "25  0.182574  0.182574  ...  0.200000  0.182574  0.000000  0.000000  0.000000   \n",
      "26  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "27  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "28  0.166667  0.166667  ...  0.182574  0.166667  0.000000  0.000000  0.000000   \n",
      "\n",
      "     24        25   26   27        28  \n",
      "0   0.0  0.000000  0.0  0.0  0.000000  \n",
      "1   0.0  0.000000  0.0  0.0  0.000000  \n",
      "2   0.0  0.200000  0.0  0.0  0.182574  \n",
      "3   0.0  0.000000  0.0  0.0  0.000000  \n",
      "4   0.0  0.000000  0.0  0.0  0.000000  \n",
      "5   0.0  0.000000  0.0  0.0  0.000000  \n",
      "6   0.0  0.400000  0.0  0.0  0.000000  \n",
      "7   0.0  0.182574  0.0  0.0  0.333333  \n",
      "8   0.0  0.182574  0.0  0.0  0.166667  \n",
      "9   0.0  0.182574  0.0  0.0  0.166667  \n",
      "10  0.0  0.200000  0.0  0.0  0.182574  \n",
      "11  0.0  0.200000  0.0  0.0  0.182574  \n",
      "12  0.0  0.200000  0.0  0.0  0.182574  \n",
      "13  0.0  0.000000  0.0  0.0  0.000000  \n",
      "14  0.0  0.000000  0.0  0.0  0.000000  \n",
      "15  0.0  0.000000  0.0  0.0  0.000000  \n",
      "16  0.0  0.000000  0.0  0.0  0.000000  \n",
      "17  0.0  0.223607  0.0  0.0  0.204124  \n",
      "18  0.0  0.169031  0.0  0.0  0.154303  \n",
      "19  0.0  0.200000  0.0  0.0  0.182574  \n",
      "20  0.0  0.182574  0.0  0.0  0.166667  \n",
      "21  0.0  0.000000  0.0  0.0  0.000000  \n",
      "22  0.0  0.000000  0.0  0.0  0.000000  \n",
      "23  0.0  0.000000  0.0  0.0  0.000000  \n",
      "24  1.0  0.000000  0.0  0.0  0.000000  \n",
      "25  0.0  1.000000  0.0  0.0  0.182574  \n",
      "26  0.0  0.000000  1.0  0.0  0.000000  \n",
      "27  0.0  0.000000  0.0  1.0  0.000000  \n",
      "28  0.0  0.182574  0.0  0.0  1.000000  \n",
      "\n",
      "[29 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Convert to term frequency matrix\n",
    "vectorizer = CountVectorizer()\n",
    "tf_matrix = vectorizer.fit_transform(df['cleaned_documents'])\n",
    "\n",
    "# Compute cosine similarity for all pairs\n",
    "cosine_sim_matrix = cosine_similarity(tf_matrix)\n",
    "\n",
    "print(\"Cosine Similarity Matrix:\")\n",
    "print(\"::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\")\n",
    "print(\"::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\")\n",
    "print(\"::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\")\n",
    "print(\"::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\")\n",
    "print(pd.DataFrame(cosine_sim_matrix, columns=df.index, index=df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df469c0-78ff-47d9-8195-b294b9fd2181",
   "metadata": {},
   "source": [
    "# **Apply Jaccard Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77844875-3406-45f7-8fa3-4f45c2f733d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity Matrix:\n",
      "...............................................................\n",
      "          0         1         2         3    4         5         6         7   \\\n",
      "0        1.0  0.285714  0.285714      0.25  0.0       0.1       0.0      0.25   \n",
      "1   0.285714       1.0      0.25       0.1  0.0       0.0       0.0     0.375   \n",
      "2   0.285714      0.25       1.0       0.1  0.0       0.0       0.0     0.375   \n",
      "3       0.25       0.1       0.1       1.0  0.0  0.181818       0.1  0.090909   \n",
      "4        0.0       0.0       0.0       0.0  1.0       0.0       0.0       0.0   \n",
      "5        0.1       0.0       0.0  0.181818  0.0       1.0  0.090909       0.0   \n",
      "6        0.0       0.0       0.0       0.1  0.0  0.090909       1.0       0.0   \n",
      "7       0.25     0.375     0.375  0.090909  0.0       0.0       0.0       1.0   \n",
      "8        0.0       0.0  0.222222  0.090909  0.0       0.0       0.0  0.090909   \n",
      "9   0.111111       0.0       0.1       0.0  0.0  0.083333       0.0  0.090909   \n",
      "10       0.0       0.0  0.111111       0.0  0.0       0.0       0.0       0.1   \n",
      "11       0.0       0.0  0.111111       0.0  0.0       0.0       0.0       0.1   \n",
      "12       0.0       0.0  0.111111       0.0  0.0       0.0       0.0       0.1   \n",
      "13     0.125       0.0       0.0       0.0  0.0  0.090909       0.0       0.0   \n",
      "14       0.0       0.0       0.0       0.0  0.0       0.0       0.0       0.0   \n",
      "15       0.0       0.0       0.0       0.0  0.0       0.0       0.0       0.0   \n",
      "16       0.0       0.0       0.0       0.0  0.0       0.0       0.0       0.0   \n",
      "17       0.0     0.125     0.125       0.0  0.0       0.0       0.0  0.111111   \n",
      "18       0.1       0.0       0.2       0.0  0.0  0.166667       0.0  0.083333   \n",
      "19       0.0       0.0  0.111111       0.0  0.0       0.0       0.0       0.1   \n",
      "20  0.111111       0.0       0.1       0.0  0.0  0.083333       0.0  0.090909   \n",
      "21     0.125  0.111111  0.111111       0.0  0.0       0.0       0.0       0.1   \n",
      "22  0.142857     0.125     0.125       0.0  0.0       0.0       0.0  0.111111   \n",
      "23  0.142857     0.125     0.125       0.0  0.0       0.0       0.0  0.111111   \n",
      "24       0.0       0.0       0.0       0.0  0.0       0.0       0.0       0.0   \n",
      "25       0.0       0.0  0.111111       0.0  0.0       0.0      0.25       0.1   \n",
      "26       0.0       0.0       0.0       0.0  0.0       0.0       0.0       0.0   \n",
      "27       0.0       0.0       0.0       0.0  0.0       0.0       0.0       0.0   \n",
      "28       0.0       0.0       0.1       0.0  0.0       0.0       0.0       0.2   \n",
      "\n",
      "          8         9   ...        19        20        21        22        23  \\\n",
      "0        0.0  0.111111  ...       0.0  0.111111     0.125  0.142857  0.142857   \n",
      "1        0.0       0.0  ...       0.0       0.0  0.111111     0.125     0.125   \n",
      "2   0.222222       0.1  ...  0.111111       0.1  0.111111     0.125     0.125   \n",
      "3   0.090909       0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "4        0.0       0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "5        0.0  0.083333  ...       0.0  0.083333       0.0       0.0       0.0   \n",
      "6        0.0       0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "7   0.090909  0.090909  ...       0.1  0.090909       0.1  0.111111  0.111111   \n",
      "8        1.0  0.090909  ...  0.222222  0.090909       0.0       0.0       0.0   \n",
      "9   0.090909       1.0  ...       0.1  0.333333       0.0       0.0       0.0   \n",
      "10       0.1       0.1  ...  0.111111       0.1       0.0       0.0       0.0   \n",
      "11       0.1       0.1  ...  0.111111       0.1       0.0       0.0       0.0   \n",
      "12       0.1       0.1  ...  0.111111       0.1       0.0       0.0       0.0   \n",
      "13       0.0       0.1  ...       0.0       0.1       0.0       0.0       0.0   \n",
      "14       0.0  0.111111  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "15       0.0       0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "16       0.0       0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "17  0.111111  0.111111  ...     0.125  0.111111       0.0       0.0       0.0   \n",
      "18       0.3  0.181818  ...  0.090909  0.181818       0.0       0.0       0.0   \n",
      "19  0.222222       0.1  ...       1.0       0.1       0.0       0.0       0.0   \n",
      "20  0.090909  0.333333  ...       0.1       1.0       0.0       0.0       0.0   \n",
      "21       0.0       0.0  ...       0.0       0.0       1.0     0.125     0.125   \n",
      "22       0.0       0.0  ...       0.0       0.0     0.125       1.0  0.142857   \n",
      "23       0.0       0.0  ...       0.0       0.0     0.125  0.142857       1.0   \n",
      "24       0.0       0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "25       0.1       0.1  ...  0.111111       0.1       0.0       0.0       0.0   \n",
      "26       0.0       0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "27       0.0       0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "28  0.090909  0.090909  ...       0.1  0.090909       0.0       0.0       0.0   \n",
      "\n",
      "     24        25   26   27        28  \n",
      "0   0.0       0.0  0.0  0.0       0.0  \n",
      "1   0.0       0.0  0.0  0.0       0.0  \n",
      "2   0.0  0.111111  0.0  0.0       0.1  \n",
      "3   0.0       0.0  0.0  0.0       0.0  \n",
      "4   0.0       0.0  0.0  0.0       0.0  \n",
      "5   0.0       0.0  0.0  0.0       0.0  \n",
      "6   0.0      0.25  0.0  0.0       0.0  \n",
      "7   0.0       0.1  0.0  0.0       0.2  \n",
      "8   0.0       0.1  0.0  0.0  0.090909  \n",
      "9   0.0       0.1  0.0  0.0  0.090909  \n",
      "10  0.0  0.111111  0.0  0.0       0.1  \n",
      "11  0.0  0.111111  0.0  0.0       0.1  \n",
      "12  0.0  0.111111  0.0  0.0       0.1  \n",
      "13  0.0       0.0  0.0  0.0       0.0  \n",
      "14  0.0       0.0  0.0  0.0       0.0  \n",
      "15  0.0       0.0  0.0  0.0       0.0  \n",
      "16  0.0       0.0  0.0  0.0       0.0  \n",
      "17  0.0     0.125  0.0  0.0  0.111111  \n",
      "18  0.0  0.090909  0.0  0.0  0.083333  \n",
      "19  0.0  0.111111  0.0  0.0       0.1  \n",
      "20  0.0       0.1  0.0  0.0  0.090909  \n",
      "21  0.0       0.0  0.0  0.0       0.0  \n",
      "22  0.0       0.0  0.0  0.0       0.0  \n",
      "23  0.0       0.0  0.0  0.0       0.0  \n",
      "24  1.0       0.0  0.0  0.0       0.0  \n",
      "25  0.0       1.0  0.0  0.0       0.1  \n",
      "26  0.0       0.0  1.0  0.0       0.0  \n",
      "27  0.0       0.0  0.0  1.0       0.0  \n",
      "28  0.0       0.1  0.0  0.0       1.0  \n",
      "\n",
      "[29 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity_set(doc1, doc2):\n",
    "    set1, set2 = set(doc1.split()), set(doc2.split())\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union\n",
    "\n",
    "# Pairwise Jaccard similarity\n",
    "jaccard_sim_matrix = pd.DataFrame(index=df.index, columns=df.index)\n",
    "\n",
    "for i in df.index:\n",
    "    for j in df.index:\n",
    "        jaccard_sim_matrix.iloc[i, j] = jaccard_similarity_set(\n",
    "            df['cleaned_documents'][i], df['cleaned_documents'][j]\n",
    "        )\n",
    "\n",
    "print(\"Jaccard Similarity Matrix:\")\n",
    "print(\"...............................................................\")\n",
    "print(jaccard_sim_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c2d064-d95e-41e7-a9a0-aa5179efbc5a",
   "metadata": {},
   "source": [
    "# **Apply Euclidean Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60282950-676e-4882-b89d-1a22ecaddad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distance Matrix:\n",
      "..........................................................................\n",
      "          0         1         2         3         4         5         6   \\\n",
      "0        0.0  2.236068  2.236068   2.44949  2.828427  2.828427       3.0   \n",
      "1   2.236068       0.0   2.44949       3.0       3.0  3.316625  3.162278   \n",
      "2   2.236068   2.44949       0.0       3.0       3.0  3.316625  3.162278   \n",
      "3    2.44949       3.0       3.0       0.0  3.162278  2.828427       3.0   \n",
      "4   2.828427       3.0       3.0  3.162278       0.0  3.162278       3.0   \n",
      "5   2.828427  3.316625  3.316625  2.828427  3.162278       0.0       3.0   \n",
      "6        3.0  3.162278  3.162278       3.0       3.0       3.0       0.0   \n",
      "7    2.44949  2.236068  2.236068  3.162278  3.162278  3.464102  3.316625   \n",
      "8   3.162278  3.316625  2.645751  3.162278  3.162278  3.464102  3.316625   \n",
      "9   2.828427  3.316625       3.0  3.464102  3.162278  3.162278  3.316625   \n",
      "10       3.0  3.162278  2.828427  3.316625       3.0  3.316625  3.162278   \n",
      "11       3.0  3.162278  2.828427  3.316625       3.0  3.316625  3.162278   \n",
      "12       3.0  3.162278  2.828427  3.316625       3.0  3.316625  3.162278   \n",
      "13  2.645751  3.162278  3.162278  3.316625       3.0       3.0  3.162278   \n",
      "14  2.828427       3.0       3.0  3.162278  2.828427  3.162278       3.0   \n",
      "15  2.828427       3.0       3.0  3.162278  2.828427  3.162278       3.0   \n",
      "16  2.828427       3.0       3.0  3.162278  2.828427  3.162278       3.0   \n",
      "17  2.828427  2.645751  2.645751  3.162278  2.828427  3.162278       3.0   \n",
      "18       3.0  3.464102  2.828427  3.605551  3.316625       3.0  3.464102   \n",
      "19       3.0  3.162278  2.828427  3.316625       3.0  3.316625  3.162278   \n",
      "20  2.828427  3.316625       3.0  3.464102  3.162278  3.162278  3.316625   \n",
      "21  2.645751  2.828427  2.828427  3.316625       3.0  3.316625  3.162278   \n",
      "22   2.44949  2.645751  2.645751  3.162278  2.828427  3.162278       3.0   \n",
      "23       3.0  3.162278  3.162278  3.605551  3.316625  3.605551  3.464102   \n",
      "24  3.316625  3.464102  3.464102  3.605551  3.316625  3.605551  3.464102   \n",
      "25       3.0  3.162278  2.828427  3.316625       3.0  3.316625   2.44949   \n",
      "26  2.828427       3.0       3.0  3.162278  2.828427  3.162278       3.0   \n",
      "27       3.0  3.162278  3.162278  3.316625       3.0  3.316625  3.162278   \n",
      "28  3.162278  3.316625       3.0  3.464102  3.162278  3.464102  3.316625   \n",
      "\n",
      "          7         8         9   ...        19        20        21        22  \\\n",
      "0    2.44949  3.162278  2.828427  ...       3.0  2.828427  2.645751   2.44949   \n",
      "1   2.236068  3.316625  3.316625  ...  3.162278  3.316625  2.828427  2.645751   \n",
      "2   2.236068  2.645751       3.0  ...  2.828427       3.0  2.828427  2.645751   \n",
      "3   3.162278  3.162278  3.464102  ...  3.316625  3.464102  3.316625  3.162278   \n",
      "4   3.162278  3.162278  3.162278  ...       3.0  3.162278       3.0  2.828427   \n",
      "5   3.464102  3.464102  3.162278  ...  3.316625  3.162278  3.316625  3.162278   \n",
      "6   3.316625  3.316625  3.316625  ...  3.162278  3.316625  3.162278       3.0   \n",
      "7        0.0  3.162278  3.162278  ...       3.0  3.162278       3.0  2.828427   \n",
      "8   3.162278       0.0  3.162278  ...  2.645751  3.162278  3.316625  3.162278   \n",
      "9   3.162278  3.162278       0.0  ...       3.0   2.44949  3.316625  3.162278   \n",
      "10       3.0       3.0       3.0  ...  2.828427       3.0  3.162278       3.0   \n",
      "11       3.0       3.0       3.0  ...  2.828427       3.0  3.162278       3.0   \n",
      "12       3.0       3.0       3.0  ...  2.828427       3.0  3.162278       3.0   \n",
      "13  3.316625  3.316625       3.0  ...  3.162278       3.0  3.162278       3.0   \n",
      "14  3.162278  3.162278  2.828427  ...       3.0  3.162278       3.0  2.828427   \n",
      "15  3.162278  3.162278  3.162278  ...       3.0  3.162278       3.0  2.828427   \n",
      "16  3.162278  3.162278  3.162278  ...       3.0  3.162278       3.0  2.828427   \n",
      "17  2.828427  2.828427  2.828427  ...  2.645751  2.828427       3.0  2.828427   \n",
      "18  3.316625  2.645751       3.0  ...  3.162278       3.0  3.464102  3.316625   \n",
      "19       3.0  2.645751       3.0  ...       0.0       3.0  3.162278       3.0   \n",
      "20  3.162278  3.162278   2.44949  ...       3.0       0.0  3.316625  3.162278   \n",
      "21       3.0  3.316625  3.316625  ...  3.162278  3.316625       0.0  2.645751   \n",
      "22  2.828427  3.162278  3.162278  ...       3.0  3.162278  2.645751       0.0   \n",
      "23  3.316625  3.605551  3.605551  ...  3.464102  3.605551  3.162278       3.0   \n",
      "24  3.605551  3.605551  3.605551  ...  3.464102  3.605551  3.464102  3.316625   \n",
      "25       3.0       3.0       3.0  ...  2.828427       3.0  3.162278       3.0   \n",
      "26  3.162278  3.162278  3.162278  ...       3.0  3.162278       3.0  2.828427   \n",
      "27  3.316625  3.316625  3.316625  ...  3.162278  3.316625  3.162278       3.0   \n",
      "28  2.828427  3.162278  3.162278  ...       3.0  3.162278  3.316625  3.162278   \n",
      "\n",
      "          23        24        25        26        27        28  \n",
      "0        3.0  3.316625       3.0  2.828427       3.0  3.162278  \n",
      "1   3.162278  3.464102  3.162278       3.0  3.162278  3.316625  \n",
      "2   3.162278  3.464102  2.828427       3.0  3.162278       3.0  \n",
      "3   3.605551  3.605551  3.316625  3.162278  3.316625  3.464102  \n",
      "4   3.316625  3.316625       3.0  2.828427       3.0  3.162278  \n",
      "5   3.605551  3.605551  3.316625  3.162278  3.316625  3.464102  \n",
      "6   3.464102  3.464102   2.44949       3.0  3.162278  3.316625  \n",
      "7   3.316625  3.605551       3.0  3.162278  3.316625  2.828427  \n",
      "8   3.605551  3.605551       3.0  3.162278  3.316625  3.162278  \n",
      "9   3.605551  3.605551       3.0  3.162278  3.316625  3.162278  \n",
      "10  3.464102  3.464102  2.828427       3.0  3.162278       3.0  \n",
      "11  3.464102  3.464102  2.828427       3.0  3.162278       3.0  \n",
      "12  3.464102  3.464102  2.828427       3.0  3.162278       3.0  \n",
      "13  3.464102  3.464102  3.162278       3.0  3.162278  3.316625  \n",
      "14  3.316625  3.316625       3.0  2.828427       3.0  3.162278  \n",
      "15  3.316625  3.316625       3.0  2.828427       3.0  3.162278  \n",
      "16  3.316625  3.316625       3.0  2.828427       3.0  3.162278  \n",
      "17  3.316625  3.316625  2.645751  2.828427       3.0  2.828427  \n",
      "18  3.741657  3.741657  3.162278  3.316625  3.464102  3.316625  \n",
      "19  3.464102  3.464102  2.828427       3.0  3.162278       3.0  \n",
      "20  3.605551  3.605551       3.0  3.162278  3.316625  3.162278  \n",
      "21  3.162278  3.464102  3.162278       3.0  3.162278  3.316625  \n",
      "22       3.0  3.316625       3.0  2.828427       3.0  3.162278  \n",
      "23       0.0  3.741657  3.464102  3.316625  3.464102  3.605551  \n",
      "24  3.741657       0.0  3.464102  3.316625  3.464102  3.605551  \n",
      "25  3.464102  3.464102       0.0       3.0  3.162278       3.0  \n",
      "26  3.316625  3.316625       3.0       0.0       3.0  3.162278  \n",
      "27  3.464102  3.464102  3.162278       3.0       0.0  3.316625  \n",
      "28  3.605551  3.605551       3.0  3.162278  3.316625       0.0  \n",
      "\n",
      "[29 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Euclidean distance for term frequency vectors\n",
    "euclidean_dist_matrix = pd.DataFrame(index=df.index, columns=df.index)\n",
    "\n",
    "for i in df.index:\n",
    "    for j in df.index:\n",
    "        euclidean_dist_matrix.iloc[i, j] = euclidean(\n",
    "            tf_matrix[i].toarray()[0], tf_matrix[j].toarray()[0]\n",
    "        )\n",
    "\n",
    "print(\"Euclidean Distance Matrix:\")\n",
    "print(\"..........................................................................\")\n",
    "print(euclidean_dist_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a3e53d-ac0d-45f3-b671-e505fb201fc0",
   "metadata": {},
   "source": [
    "# **Apply Semantic Similarity**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba4126-05c6-4a85-a611-abde99b534cf",
   "metadata": {},
   "source": [
    "import spacy\n",
    "\n",
    "# Load a pre-trained word embeddings model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Compute semantic similarity for all pairs\n",
    "semantic_sim_matrix = pd.DataFrame(index=df.index, columns=df.index)\n",
    "\n",
    "for i in df.index:\n",
    "    for j in df.index:\n",
    "        doc1, doc2 = nlp(df['cleaned_documents'][i]), nlp(df['cleaned_documents'][j])\n",
    "        semantic_sim_matrix.iloc[i, j] = doc1.similarity(doc2)\n",
    "\n",
    "print(\"Semantic Similarity Matrix:\")\n",
    "print(semantic_sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb613de6-923f-46fa-8694-4d0410842df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
